---
title: "사이버보안 AI 빅데이터 챌린지 2022 네트워크 공격 분류 트랙"
author: JOSEOYEON
date: 2023-11-04 20:38:51
categories: [Algorithm, AI, Network, Forensic,Project]
tags: [AI Chellenge]
---

# 빅데이터 분석을 활용한 정보보안 위협 분석 

전자적 침해 행위 통합보안 관제 및 침해하고 분석 대응을 위해 빅데이터 분석을 활용한 정보보안 위협 식별 기술이 발전중이다. 
아티팩트에 근거한 악성코드 감염 경로 분석이 필요하다. 예를 들어 공격자가 작성했던 Exploit 명령어, 트래픽 등을 추적해야 한다. <BR/>

빅데이터 분석과 침해사고 분석 기술을 적용하여 웹 로그 내에서 악성 행위 데이터를 식별하는 대회 프로젝트다. 5만건 이상의 웹 로그를 분석하고, 이상 트래픽 추이 확인을 통해 공격 데이터를 식별하는 것을 목표로 한다.
 
시간별 웹 로그에서 정상행위가 95% 이상으로 식별되는 것을 이용하여 적게 나타나는 새로운 형태의 로그에 대해 우선 분석 순위를 정해 새로운 악성 시그니처를 빨리 파악할 수 있도록 아이디어를 제안 하였습니다

# 분석 4단계과정

## 1. 데이터 분석

공격 데이터 로그로만 이루어져 있었으며 TTP를 기반으로 정답 클래스가 나뉘어 각각 침입, exploit, post, unknown 클래스로 분류된 데이터가 주어졌다. 데이터 셋의 필드는 Payload, Protocol, 출발지/목적지 IP 및 PORT 등의 메타데이터가 존재하였다. <br/>
분석 및 AI 학습이 용이 하도록 전처리 작업을 진행 했다. 이후 데이터에 대한 인사이트를 얻기 위해 탐색적 데이터 분석(EDA)를 진행하여 통계 및 도메인 기반의 유의미한 정보를 확인하였으며, 공격 구문에 사용된 프로그래밍 언어를 식별 할 수 있는 Guesslang 기법을 적용했다. <br/>

* 탐색형 데이터 분석은 데이터 사이언티스트가 종종 데이터 시각화 방법을 사용하여 데이터 세트를 분석 및 조사하고 이의 주요 특징을 요약하는데 사용한다. 주요 목적은 데이터 내의 패턴을 잘 파악하고, 이상값을 발견하는 것이다. 

## 2. 특징 공학

EDA 분석을 통해 확인한 정보수집 및 공격 탐지 패턴을 특징으로 사용한다, 문자열 형식의 데이터를 특징으로 사용하기 위해 one-hot-encoding 기법을 적용하여 숫자 형태로 변환한다. 

### Feature Engineering 

* 언어 탐지(Guess Lang) <br/>
* HTTP 헤더 필드 별 길이 <br/>
* 비정상 메소드 <br/>
* Admin 포함 여부<br/>
* Directory Listing 여부<br/>
* XSS 탐지 <br/>
* Web Shell 탐지 <br/>
* 특수 문자 포함 여부 <br/>
* RDP Worm<br/>
* Well-known Port<br/>
* URL 특정 패턴 여부 <br/>
* 위험도<br/>
* Skip Fish 여부 <br/>
* Shellshock 여부 <br/>
* .cgi 확장자 여부 <br/>
* Nmap Scripting 여부 <br/>


## 3. AI 모델링

우수한 성능, 과적합에 유리, 데이터 스케일링 불필요로, 이 3가지 우수한 이유로 인해 Random Forest 알고리즘을 선정하여 파라미터 튜닝 과정을 통해 최적의 학습 트리 개수를 적용

## 4. 분류 결과

Random Forest 로 분류한 데이터의 정확도를 측정하였을 때가 클래스 별 정확도는 모두 97% 이상이며, macro 정확도는 99%를 보인다. 

# 1. 데이터 분석

## 데이터 설명

데이터 셋에는 Payload, Protocol, 출발지/목적지 IP 및 Port 등의 메타 데이터가 존재한다. 이중 Payload는 데이터마다 서로 다른 값을 가지는 경우가 많아 분석 및 AI 학습이 용이하도록 전처리 작업을 진행했다. 

### 클래스

* 정찰 : 공격을 위한 사전 정찰 및 정보 조회 관련 이벤트 <br/>
* exploit : 실제 공격을 수행하는 페이로드 중에서 최초 공격 및 감염에 해당하는 이벤트를 말한다<br/>
* post : 실제 공격을 수행하는 페이로드 중에서 정보 탈취 및 내부 침투에 해당하는 이벤트를 말한다<br/>
* unknown : 공격 데이터 생성과정에서 수집된 불특정 이벤트 <br/>


### 필드명
* 요청 URI(POST /wsman?PSVersion=7.1.3 HTTP/1.1)
* 요청 대상 request_target(/wsman?PSVersion=7.1.3)
* 사용자 에이전트 user_agent (Mozila/5.0 (Windows NT 10.0; Win64; x64))
쿠키 값 cookie (JSEESIONID=188F8C229EAD4FC819679F4ECD0789CB;)
* HTTP 메소드 http_method (GET, POST, OPTIONS)
* 비정상 특수문자 special_chars(~, <, \, : 등): 비정상 특수 문자들은 일반적인 URL에서 나타나지 않는 특수문자를 말한다. 

<br/>

여기서 쿠키란, 클라이언트 로컬에 저장되는 키와 값이 있는 작은 데이터 파일이다. 사용자 인증이 유효한 시간을 명시할 수 있으며, 유효 시간이 정해지면 브라우저가 종료되어도 인증이 유지된다는 특징이 있다. 쿠키는 클라이언트의 상태 정보를 로컬에 저장했다가 참조한다. 클라이언트에 300개까지 쿠키 저장이 가능하고, 하나의 도메인 당 20개의 값만 가질 수 있다. 하나의 쿠키 값은 4KB 까지 저장한다. Respoonse Header 에 Set-Cookie 속성을 사용하면 클라이언트에 쿠키를 만들 수 있다. 쿠키는 사용자가 따로 요청하지 않아도 브라우저가 Request 시 Request Header를 넣어서 자동으로 서버에 전송한다. 
<br/>

쿠키를 구별하는데 사용되는 이름과 쿠키의 이름과 관련된 값, 쿠키의 유지시간, 쿠키를 전송할 도메인, 쿠키를 전송한 요청 경로로 쿠키가 구성됩니다. 같은 요청을 할 경우 HTTP 헤더에 쿠키를 함께 보내 응답 속도를 높이는 역할을 합니다. 예를 들어 방문 사이트에서 로그인 시, 아이디와 비밀번호를 저장하거나 자동 로그인 팝업에서 오늘 더이상 이 창을 보지 않음을 체크하는 식으로 이 쿠키가 활용됩니다.

<br/>

## 탐색적 데이터 분석 

### 통계적 길이 기반 

이런 데이터에서 공격 패턴을 얻기 위해 탐색적 데이터 분석(EDA)를 진행하였으며 통계 및 도메인 기반의 유의미한 정보를 확인하였다.  

payload, user_agent, request_uri, cookie 등의 길이, 길이의 평균, 분산 및 표준 편차를 통해 class 구분이 가능하다. 나머지 필드는 class 로 구분이 불가능하다.  
<br/>

클래스에 따라 유사한 통계값(길이, 평균 등)을 가질 것이라는 가설을 세운 후 모든 필드를 대상으로 시각화 및 통계 분석을 진행했다. 그 결과 payload, user_agent, request_uri 및 cookie 값의 통계값으로 class 구분이 가능하다는 유의미한 결과를 얻었다. 
<br/>

특히 exploit 계층에서 payload에 공격 구문 데이터가 들어가기 때문에 400자 이상의 긴 길이로, 다른 클래스와 구분되는 긴 길이를 보였다. 평균적인 통계치는 post 공격이 가장 긴 길이를 보였고, 분산과 표준 편차 또한 post 길이가 가장 큰 편차 길이를 보였다. 
<br/>
따라서 길이가 길면 exploit 라고 확인할 수 있으며, 평균에서 차이가 큰 값이, 즉, 편차가 크면 post 라고 판단할 수 있다. 

### 도메인 기반 

네트워크 계층 정보로 source IP 와 destination IP는 대다수의 IP 가 서로 다른 값을 가져 유의미한 정보를 추출할 수 없다. source PORT와 destination PORT는 정보 수집 및 공격 의심 포트를 확인할 수 있어 유의미한 정보를 확인할 수 있다. 
 
<br/>

* port 분석 결과 <br/>
포트는 IP 내에서 애플리케이션 상호구분을 위해 사용하는 번호이며, 특정 서비스는 고정적으로 사용하는 번호(Well-Known Port)가 정해져 있다. 즉 포트 번호를 통해 어떤 서비스를 제공하는지 추측할 수 있기에 빈도수를 기반으로 분석을 진행했다. 
 
<br/>

많은 웹 사이트를 운영중인 만큼 목적지 포트가 80/8080인 빈도가 가장 높게 나왔다. 이를 대상으로 한 공격인, SQL 인젝션이나 XSS 등 웹 취약점 공격이 다수 탐지될 수 있다는 점이 유추 된다. 웹 서비스 이외의 포트 (RDP(3389)/ WinRM(5985) 등)에 통신이 연결된 흔적이 있는 것으로 보아, 정보수집 및 공격과 연관성이 큰 공격이 다수 탐지될 수 있다.

 
<br/>

Well-Known 포트(d-port < 1024>) 빈도수를 통해 HTTP 외에 특징 추출에 참고할 수 있는 포트 번호를 확인했다. 
 
<br/>

### 사용된 공격 시그니처 

* 관리자 권한에 접근시 나타나는 admin 문자열 검사 구문 <br/>
* xss 공격에 활용되는 구문(script/alert 등)을 검사<br/>
* 웹 쉘 공격에 활용되는 cmd 문자열 검사 (cmd=)<br/>
* 디렉토리 접근 공격에 활용되는 경로 이동 문자 검사(../  %2f, %5c, %255c)<br/>
* 일반적인 URL에서 나타나지 않는 비정상 특수 문자 검사 <br/>
* rdp_worm RDP 여부 및 세션 탈취 검사(mstshash=)<br/>
* sql 인젝션 공격 자동화 툴(sqlmap) 사용 검사 <br/>
* 웹 사이트 취약점 진단 자동화 툴(burpscan) 사용 검사(burpcollab 등) <br/>
* manage_url인 /manager/html 문자열 검사 <br/>
* 네트워크 스캔 툴인 nmap 사용 검사 <br/>
* ipcheck라고 하는 ip 정보 수집 검사 <br/>
* 스캔 툴인 skipfish 사용 검사 <br/>
* shellshock 취약점 익스플로잇에 사용되는 구문 검사 () {ㅣ;}; <br/>
* cgi 문자열 검사 <br/>
* 정상적인 http 메소드 검사(GET / POST / HEAD / OPTIONS /DELETE / PUT / CONNECT / TRACE / PATCH) <br/>
* 비정상적인 HTTP 메소드 검사 


### 공격 패킷의 언어 감지

EDA 과정을 거치며 대부분의 공격 로그가 특정 언어나 스크립트를 사용한다는 점을  확인했으며, 공격 로그를 보고 어떤 프로그래밍 언어를 사용한 공격인지 식별할 수 있는 데이터가 필요하다고 판단했다. <br/> GuessLang이라고 하는 소스코드의 프로그래밍 언어르 감지하는 PYTHON 모듈로 소스코드 텍스트가 들어오면 해당 코드의 유형을 문자열 형태로 반환한다. 

# 2. 특징 공학

## ONE HOT ENCODING

트리 계열의 알고리즘은 숫자로된 데이터를 받았을 때 대부분 *연속형 데이터*로 인식하기 때문에 이를 변환해 주는 작업이 필요했다. 따라서 가장 대표적인 인코딩 방법인 one-hot-encoding 을 사용했다. one-hot-encoding 이란 단어 집합에 고유한 정수를 부여하고, 표현하고 싶은 단어의 인덱스에는 1의 값을 다른 단어의 값은 0을 부여한다. 이 기법을 이용하여 guesslang을 통해 추출된 언어 정보 중 cmd/powershell 스크립트로 탐지된 경우에 1을 부여했다. http method의 경우에도 get, post, options 등의 정상적인 메소드 사용이 아니라 다른 유형의 메소드 텍스트로 나타나는 경우에는 1이 아니라 0을 부여했다. 특수문자의 포함여부와, 공격 시그니처를 인자로 받아 있는지 여부를 boolean 값으로 나타냈다.
<br/>


# 3. AI 알고리즘 구성 

Random Forest 는 여러개의 결정 트리를 활용한 배깅 방식의 대표적인 알고리즘이다. <br/>
1. 동일한 알고리즘을 사용하는 일정 수의 분류기를 생성<br/>
2. 각각의 분류기는 부트스트래핑 방식(전체 데이터에서 일부 데이터의 중첩을 허용하는 방식)으로 생성된 샘플 데이터를 학습<br/>
3. 최종적으로 모든 분류기가 보팅을 통해 예측을 결정한다. <br/>

![image](https://user-images.githubusercontent.com/46625602/280462212-31883240-bcfa-47e1-96b6-25ef0c28ed24.png)

<br/>

Random Forest 를 사용한 이유는 3가지이다. <br/>

1. 우수한 성능 <br/>
- Random Forest 알고리즘은 보편적이면서 성능이 매우 우수하며, 대회 및 현업에서 많이 사용하는 알고리즘 중 하나다. 표준적으로 많이 알고리즘인 만큼 특징 공학의 적합성을 효과적으로 입증할 수 있고, 향후 다른 데이터 셋으로의 확장을 고려했을 때 가장 객관적인 지표로써 보여질 수 있다. <br/>

2. 과적합에 유리 <br/>
- Random Forest 알고리즘은 과적합에 유리하다. 개별 트리를 배깅 방식으로 훈련시켜 그 결과를 종합적으로 추출해 주기 때문에 예측 모델의 안정성을 보장해 준다. 이러한 특성은 보안 도메인에서 가장 적절하게 작용하는데, 학습셋을 구축하기 어려운 보안 로그는 다른 비즈니스 모델링에 비해 적은 양의 데이터 셋으로 학습이 진행될 수 밖에 없다. 학습 셋이 적을 수록 과적합이 크게 나타나며 이는 장기적인 모델 운영의 관점에서 가장 큰 문제점으로 작용한다. 따라서 이러한 과적합을 최소한으로 줄여줄 모델로 적합하다. <br/>

3. 데이터 스케일링 불필요 <br/>
- 보안 로그를 데이터 셋으로 하는 ML을 모델링 하게 되면, 결과를 추적할 때 스케릴링이 되어 있을 경우 분석하는데 어려움이 많다. 하지만, Random Forest 알고리즘은 별도의 데이터 스케일링이 불필요하여 향후 원인을 추적하고 개선하는 데에 많은 편리함이 있다. 

## 파라미터 튜닝

파라미터 튜닝의 경우, 대회 상황에 따라 유동적으로 변동될 수 있어 현재 테스트 기준으로 가장 적절한 경우를 선정하였다. 

- 학습 트리 개수 선정 (n_estimators) <br/>
학습 트리의 개수를 최소 50개 부터 최대 500 개까지 테스트하였을 때, 정확도에 변화가 없음을 확인하였다. <br/>

- 최대 깊이 선정(max_depth) <br/>
학습할 트리별 최대 깊이를 선정하는 부분이다. 최대 깊이는 적을 수록 과적합 방지에 유리하며, 훈련 셋과 테스트 셋의 차이가 가장 작으면서 정확도가 안정적인 구간을 선택하는 것이 좋다. <br/>

- 분리 노드의 최소 자료 후 <br/>
분리 노드의 최소 자료 수는 많을 수록 과적합 방지에 유리하다. 따라서 분리 노드의 최소 자료수는 많되 학습 데이터 기반 모델 정확도와 테스트 데이터 기반 모델 정확도의 차이가 적은 값으로 선정하였다. 그림에 의하면 분리 노드의 개수가 18개일 때 조건을 충족시켜 18로 선정하였다. <br/>

# 4.분류 결과 

reconnaissance는 97%의 정확도를 보이며, 이를 제외한 클래스는 99%이상의 정확도를 보인다. 

## 차원의 저주 문제 

차원의 저주는 학습을 위한 데이터의 차원이 커질 수록 성능이 하락하는 현상을 의미한다. 차원은 곧 연산에 사용되는 변수의 수를 의미하기 때문에 차원이 커진다는 것은 연산량의 증가로 이어진다. 제공된 데이터 셋 분석을 통해 추출한 모든 특징들을 AI 학습에 사용하였으나 과도한 차원수로 인해 급격한 연산 속도 저하가 발행했다. <br/>

### 해결 과정
-  널값 제거<br/>
차원의 수를 줄이기 위해 먼저 모든 데이터가 null 또는 0 값을 가지는 특징을 찾았다. 이들은 데이터의 클래스를 구별하는데 도움을 주지 못하고 차원의 수만 늘리기 때문에 연산량을 줄이고자 제거하였다. <br/>
- 특징 별 중요도 측정<br/>
학습에 사용할 특징의 수를 줄이기 위해 특징별 중요도를 계산하는 방법을 사용했다. 이를 통해 상대적으로 영향을 많이 준 특징을 선별하고 영향을 주지 않은 특징은 제외했다.<br/> 

## 과적합 문제(Overfitting)

과적합은 머신 러닝 모델이 학습 데이터를 과하게 학습하는 것을 의미한다. 과적합이 일어난 모델은 학습 데이터에 대해서는 높은 정확도를 보이지만 실제 데이터에 대해서는 높은 정확도를 보이지 못하며, 결과적으로 모델의 성능이 저하되는 현상이 발생한다. 

### 해결 과정
- 주어진 데이터의 통계적 특징 활용 
학습 데이터에서 추출한 특징이 예선 데이터에 동일하게 나타나지 않을 가능성이 존재했기 때문에 특징 탐지에 유연성을 부여하고자 했다. 사용된 특징은 단순히 데이터에서 추출한 포트 번호와 URL 내 특정 문자열의 존재 여부 뿐만 아니라 Guesslang을 활용한 자동 언어 탐지, 파라미터 통계값등을 AI 모델에 적용했다.  


---

**Refference**

